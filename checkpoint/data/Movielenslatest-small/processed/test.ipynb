{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "d = pickle.load(open('ml_latest-small_core_10_type_hete.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# unique, counts = np.unique(d['edge_index_nps']['user2item'][0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../raw/raw_movies.csv', sep=';').fillna('')\n",
    "ratings = pd.read_csv('../raw/raw_ratings.csv', sep=';')\n",
    "tagging = pd.read_csv('../raw/raw_tagging.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_df_mlsmall(movies, ratings, tagging):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        movies:\n",
    "        ratings:\n",
    "        tagging:\n",
    "        genome_tagging:\n",
    "        genome_tags:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Reindex uid\n",
    "    unique_uids = np.sort(ratings.uid.unique()).astype(np.int)\n",
    "    uids = np.arange(unique_uids.shape[0]).astype(np.int)\n",
    "    raw_uid2uid = {raw_uid: uid for raw_uid, uid in zip(unique_uids, uids)}\n",
    "    ratings['uid'] = np.array([raw_uid2uid[raw_uid] for raw_uid in ratings.uid], dtype=np.int)\n",
    "    tagging['uid'] = np.array([raw_uid2uid[raw_uid] for raw_uid in tagging.uid], dtype=np.int)\n",
    "\n",
    "    # Reindex iid\n",
    "    unique_iids = np.sort(movies.iid.unique()).astype(np.int)\n",
    "    iids = np.arange(unique_iids.shape[0]).astype(np.int)\n",
    "    raw_iid2iid = {raw_iid: iid for raw_iid, iid in zip(unique_iids, iids)}\n",
    "    movies['iid'] = np.array([raw_iid2iid[raw_iid] for raw_iid in movies.iid], dtype=np.int)\n",
    "    ratings['iid'] = np.array([raw_iid2iid[raw_iid] for raw_iid in ratings.iid], dtype=np.int)\n",
    "    tagging['iid'] = np.array([raw_iid2iid[raw_iid] for raw_iid in tagging.iid], dtype=np.int)\n",
    "\n",
    "    # Create tid\n",
    "    unique_tags = np.sort(tagging.tag.unique()).astype(np.str)\n",
    "    tids = np.arange(unique_tags.shape[0]).astype(np.int)\n",
    "    tags = pd.DataFrame({'tid': tids, 'tag': unique_tags})\n",
    "    tag2tid = {tag: tid for tag, tid in zip(unique_tags, tids)}\n",
    "    tagging['tid'] = np.array([tag2tid[tag] for tag in tagging.tag], dtype=np.int)\n",
    "    tagging = tagging.drop(columns=['tag'])\n",
    "\n",
    "    return movies, ratings, tagging, tags\n",
    "\n",
    "num_feat_core = 10\n",
    "num_core = 10\n",
    "\n",
    "movies = movies.drop_duplicates()\n",
    "ratings = ratings.drop_duplicates()\n",
    "tagging = tagging.drop_duplicates()\n",
    "\n",
    "movies = movies[movies.iid.isin(ratings.iid.unique())]\n",
    "ratings = ratings[ratings.iid.isin(movies.iid.unique())]\n",
    "tagging = tagging[tagging.iid.isin(ratings.iid.unique())]\n",
    "tagging = tagging[tagging.uid.isin(ratings.uid.unique())]\n",
    "\n",
    "movie_count = ratings['iid'].value_counts()\n",
    "movie_count.name = 'movie_count'\n",
    "ratings = ratings[ratings.join(movie_count, on='iid').movie_count > num_core]\n",
    "\n",
    "user_count = ratings['uid'].value_counts()\n",
    "user_count.name = 'user_count'\n",
    "ratings = ratings[ratings.join(user_count, on='uid').user_count > num_core]\n",
    "\n",
    "movies = movies[movies.iid.isin(ratings.iid.unique())]\n",
    "tagging = tagging[tagging.iid.isin(ratings.iid.unique())]\n",
    "tagging = tagging[tagging.uid.isin(ratings.uid.unique())]\n",
    "\n",
    "tag_count = tagging['tag'].value_counts()\n",
    "tag_count.name = 'tag_count'\n",
    "tagging = tagging[tagging.join(tag_count, on='tag').tag_count > num_feat_core]\n",
    "\n",
    "years = movies.year.to_numpy()\n",
    "years[years < 1950] = 1950\n",
    "movies['year'] = years\n",
    "\n",
    "years = movies.year.to_numpy().astype(np.int)\n",
    "min_year = min(years)\n",
    "max_year = max(years)\n",
    "num_years = (max_year - min_year) // 10\n",
    "discretized_years = [min_year + i * 10 for i in range(num_years + 1)]\n",
    "for i in range(len(discretized_years) - 1):\n",
    "    years[(discretized_years[i] <= years) & (years < discretized_years[i + 1])] = str(\n",
    "    discretized_years[i])\n",
    "    years[years < discretized_years[0]] = discretized_years[0]\n",
    "    years[years >= discretized_years[-1]] = discretized_years[-1]\n",
    "\n",
    "movies['year'] = years\n",
    "\n",
    "movies, ratings, tagging, tags = reindex_df_mlsmall(\n",
    "                    movies, ratings, tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.sort_values('timestamp')\n",
    "# ratings = ratings.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 55 54.55 26.63\n",
      "1 55 54.55 39.15\n",
      "2 44 68.18 66.75\n",
      "3 29 103.45 101.18\n",
      "4 18 166.67 158.06\n",
      "5 31 96.77 105.44\n",
      "6 39 76.92 88.71\n",
      "7 29 103.45 107.94\n",
      "8 31 96.77 136.9\n",
      "9 28 107.14 108.54\n",
      "10 36 83.33 132.79\n",
      "11 40 75.0 112.99\n",
      "12 33 90.91 152.89\n",
      "13 34 88.24 150.04\n",
      "14 35 85.71 91.41\n",
      "15 40 75.0 125.48\n",
      "16 42 71.43 109.72\n",
      "17 54 55.56 75.02\n",
      "18 41 73.17 99.54\n",
      "19 44 68.18 64.19\n",
      "20 34 88.24 138.2\n",
      "21 35 85.71 129.39\n",
      "22 34 88.24 120.1\n",
      "23 34 88.24 162.11\n",
      "24 37 81.08 189.6\n"
     ]
    }
   ],
   "source": [
    "tf_size = 3000\n",
    "\n",
    "for i in range(25):\n",
    "    # print(i)\n",
    "    tf = ratings[i*tf_size:(i+1)*tf_size]\n",
    "    # print(len(tf['uid'].unique()))\n",
    "    counts = tf['uid'].value_counts().to_numpy()\n",
    "    # print(f'std: {np.std(counts)} mean: {np.mean(counts)}')\n",
    "    print(f'{i} {len(tf[\"uid\"].unique())} {round(np.mean(counts), 2)} {round(np.std(counts), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = ratings['uid'].value_counts().to_numpy()\n",
    "print(f'cv: {np.mean(counts)/np.std(counts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings['uid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.groupby(\"uid\").count().iid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
